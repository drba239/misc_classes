\documentclass[12pt]{article}
\include{../../../preamble.tex}

\pagestyle{fancy}   % use the fancy page style
\fancyhf{}          % clear all header and footer fields

% Define the header
\lhead{Dylan Baker}    % left header
\chead{}             % center header (empty)
\rhead{``Tradeoffs and Comparison Complexity'' Referee Report} % right header
\cfoot{\thepage}

\author{Dylan Baker}

\begin{document}

\textbf{Summary of Paper}

``Tradeoffs and Comparison Complexity''
examines the role of tradeoffs 
in informing comparison complexity.
The authors propose
a theory of comparison complexity 
and flesh out its details
in the context of 
multiattribute, lottery, and intertemporal choice.
The authors model 
a decision maker (DM) who faces a set of alternatives 
and receives a noisy signal concerning their 
value, which is informed by the ease of comparison
between alternatives, $\tau_{xy}$ for 
alternatives $x$ and $y$.
The authors ground their theory in two 
reasonably simple principles: 
comparisons are easier when alternatives are similar
and are maximally easy when one alternative dominates the other.
Importantly, the authors take 
the comparability of alternatives to be 
an increasing transformation of the 
value-dissimilarity ratio,
$\frac{\left|v_x-v_y\right|}{d(x, y)}$, where 
the numerator is the difference in the 
value of alternatives $x$ and $y$
and the denominator is their dissimilarity.

In elaborating on their theory in the context of 
their three aforementioned settings,
the authors provide more structure on 
the components of the value-dissimilarity ratio 
and the probability 
of making a given choice, as well as provide 
axiomatic foundations for their characterizations.
Through this setup, the authors offer 
a tractable model with parameters 
identifiable from binary choice data.
They then extend this setup to 
multinomial choice. The model 
presented by the authors has a number of 
interesting implications, including
that comparison complexity leads to noisy but 
unbiased choice under binary menus, but 
produces systematic biases in larger menus due to 
differences in the ease of comparison 
of any two options against the rest of the menu.
The authors argue that the principles 
embedded in their model can rationalize context effects, 
preference reversals, probability weighting, 
and hyperbolic discounting.

The authors put the predictions of their model to the 
test in a series of experiments that span the 
three settings they consider.
First, as a form of validation, 
the authors show that their proposed 
complexity measures are predictive of 
of choice noise and errors.
Second, the authors demonstrate that they can 
eliminate common preference reversals
by reducing comparison complexity.
Finally, they demonstrate that they can 
flip 
the standard results from 
probability weighting and hyperbolic discounting
by eliciting valuations in terms of 
probability and time equivalents,
and hence switching the dynamics of 
what alternatives are easily comparable.
Moreover, the authors conduct an exercise
of benchmarking their model 
against existing models,
showing that it performs as well or better in 
terms of explaining the data's variation, 
without sacrificing parsimony, as measured 
by a restrictiveness exercise.

The authors then apply their model 
to study strategic obfuscation in markets. 
In examining the proliferation of 
forms of similar products varying 
qualities such as quantity and superficial features, 
they
contrast the implications of their model 
against an alternative explanation   
of heterogenous consumer preferences.
They begin by demonstrating that 
strategic obfuscation aimed at inducing 
comparison complexity can produce 
the same product proliferation result
as heterogenous preferences.
They then turn to a discussion of 
differentiating the two explanations, such 
as through the use of multinomial choice data. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Comments}

Overall, the paper is very interesting and 
offers a cohesive explanation 
for a number of important behavioral phenomena.
It has strengths in the tractability
of the model, the intuitive logic 
grounding the claims,
and the compelling experimental evidence.

\hrulefill\hspace{0.5em}\dotfill\hspace{0.5em}\hrulefill

I'm somewhat confused by
the construction of the 
signal $s_{xy}$:

\begin{align}
    & s_{x y}=\operatorname{sgn}\left(v_x-v_y\right)+\frac{1}{\sqrt{\tau_{x y}}} \epsilon_{x y}, \\
    & \epsilon_{x y} \sim N(0,1)
\end{align}

It seems like this is saying that there are 
two components of the signal outside of the noise, 
the sign of the value difference, which provides 
a discrete jump, 
and the ease of the comparison, which scales 
the noise. It seems somewhat strange that 
the change to the signal would be so discrete in the 
sign difference and that all of the information 
about the value difference beyond sign would be 
embedded within ease of comparability scaling the noise.
Perhaps this is sensible; the expression for $\rho(x,y)$
that it yields is attractive, but it would be nice 
to have more justification for this construction.


\hrulefill\hspace{0.5em}\dotfill\hspace{0.5em}\hrulefill

In the discussion of the simplification property in 
the multiple-attribute setting, 
it may be worth making it more clear that 
decreasing the number of attributes 
only weakly simplifies the comparison complexity.
This is alluded to in the footnote, though the language in the 
text and
example is such that it could be misread as strict.
An example in the same setup as used in the text where it 
would be weak is

\begin{align}
    &x = (10, 10, 10, 10) \quad &x = (10, 10, 10, 10) \\
    &y = (5, 15, 5, 15) \quad &y' = (10, 10, 0, 20)
\end{align}

It seems there are intuitive conditions under which it would 
be strict, for which it may be beneficial to lay out the logic
underpinning them.
I think this is not so important, given how it appears 
throughout the paper, but just a small point.

\hrulefill\hspace{0.5em}\dotfill\hspace{0.5em}\hrulefill

While nicely designed, there is always a question of 
external validity with this type of endeavor.
These experiments are highly stylized and 
generally quite different than the types of choices 
people face in the world, at least on some key experiential 
dimensions. For example, the authors use 
multiple price lists, which some researchers 
have expressed concern towards given 
the strange performance (e.g., multiple switching) 
many subjects exhibit in them.
I think this is ultimately fine, 
particularly given norms of the field
and the strength of the evidence, 
but, in an ideal world,
connecting these results to more naturalistic settings would be great.
I can see the discussion of the strategic
obfuscation in the market setting as a theoretical step in this direction.

\hrulefill\hspace{0.5em}\dotfill\hspace{0.5em}\hrulefill

I think it would be reasonable to spend more time justifying 
some of the functional form assumptions throughout the paper.
This could be useful even in some component pieces,
such as the $d_{L1}(x,y)$ function for 
the multi-attribute domain -- to have the coefficients on the 
attribute differences for distance be the coefficients on the
feature in the utility function has intuitive appeal,
but is of course practically a strong assumption on how
people process the information. Is this expression
sufficiently logical that we need not consider other options; alternatively, 
are the results robust to other reasonable distant metrics, etc.? 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\hrulefill\hspace{0.5em}\dotfill\hspace{0.5em}\hrulefill

This is a truly tiny thing to highlight, 
but in the 5th footnote, the final closing ``$)$''
is missing in the expression: $H(r)=\left(\Phi^{-1}(G(r))^2\right.$.



\end{document}